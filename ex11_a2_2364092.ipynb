{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnHT0tAE_ZYq",
        "outputId": "8b3848b2-7e95-4bf8-dbad-60b25bf87908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coll_of_ES_EPs.txtファイルの文字数は:\n",
            "yokohama: 1\n",
            "national: 1\n",
            "university: 1\n",
            "college: 1\n",
            "of: 1\n",
            "engineering: 5\n",
            "science: 4\n",
            "education: 1\n",
            "programs: 1\n",
            "mechanical: 1\n",
            "program: 10\n",
            "materials: 1\n",
            "and: 4\n",
            "systems: 1\n",
            "design: 1\n",
            "for: 1\n",
            "ocean: 1\n",
            "space: 1\n",
            "chemistry: 2\n",
            "applications: 1\n",
            "life: 1\n",
            "mathematical: 1\n",
            "sciences: 1\n",
            "physics: 2\n",
            "applied: 1\n",
            "electrical: 1\n",
            "computer: 2\n",
            "Dep_of_M-P-EE-CS.txtファイルの文字数は:\n",
            "1: 1\n",
            "2: 1\n",
            "3: 1\n",
            "4: 1\n",
            "a: 7\n",
            "academic: 1\n",
            "accurately: 1\n",
            "acquire: 1\n",
            "acquiring: 1\n",
            "across: 1\n",
            "active: 1\n",
            "advanced: 4\n",
            "algebra: 1\n",
            "all: 2\n",
            "also: 1\n",
            "an: 2\n",
            "analog: 1\n",
            "analytical: 1\n",
            "analytics: 1\n",
            "and: 54\n",
            "applications: 1\n",
            "applied: 5\n",
            "are: 2\n",
            "artificial: 1\n",
            "as: 6\n",
            "astroparticle: 1\n",
            "astrophysics: 1\n",
            "attention: 1\n",
            "audio: 2\n",
            "based: 1\n",
            "basic: 3\n",
            "becoming: 1\n",
            "biomedical: 1\n",
            "both: 2\n",
            "can: 2\n",
            "capability: 1\n",
            "capable: 2\n",
            "choose: 1\n",
            "circuit: 3\n",
            "circuits: 1\n",
            "classes: 1\n",
            "classical: 1\n",
            "cognition: 1\n",
            "cognitive: 1\n",
            "combination: 1\n",
            "communication: 4\n",
            "composed: 1\n",
            "computational: 1\n",
            "computer: 13\n",
            "condensed: 1\n",
            "conditions: 1\n",
            "contexts: 1\n",
            "control: 4\n",
            "cosmic: 1\n",
            "covers: 1\n",
            "creative: 1\n",
            "cultures: 1\n",
            "curriculum: 2\n",
            "data: 1\n",
            "database: 2\n",
            "deep: 1\n",
            "department: 2\n",
            "designed: 1\n",
            "develop: 1\n",
            "development: 2\n",
            "device: 1\n",
            "devices: 1\n",
            "digital: 1\n",
            "discriminative: 1\n",
            "education: 1\n",
            "educational: 1\n",
            "electric: 1\n",
            "electrical: 6\n",
            "electricity: 1\n",
            "electromagnetic: 1\n",
            "electromagnetism: 1\n",
            "electronic: 3\n",
            "electronics: 6\n",
            "elementary: 1\n",
            "energy: 1\n",
            "engineering: 15\n",
            "environment: 1\n",
            "etc: 1\n",
            "extreme: 1\n",
            "field: 3\n",
            "fields: 4\n",
            "flexible: 1\n",
            "focus: 1\n",
            "for: 2\n",
            "fosters: 1\n",
            "foundation: 1\n",
            "founded: 2\n",
            "four: 1\n",
            "from: 2\n",
            "fundamental: 2\n",
            "further: 1\n",
            "geometry: 1\n",
            "graduates: 1\n",
            "graph: 1\n",
            "graphics: 1\n",
            "green: 1\n",
            "group: 1\n",
            "handle: 1\n",
            "hardware: 1\n",
            "high: 1\n",
            "human: 4\n",
            "ideas: 1\n",
            "image: 1\n",
            "in: 8\n",
            "including: 1\n",
            "industry: 1\n",
            "informatics: 1\n",
            "information: 20\n",
            "infrastructure: 1\n",
            "innovations: 2\n",
            "integrated: 6\n",
            "intelligence: 1\n",
            "intelligent: 2\n",
            "international: 1\n",
            "is: 4\n",
            "judgment: 1\n",
            "knowledge: 2\n",
            "lab: 1\n",
            "laboratories: 1\n",
            "laboratory: 54\n",
            "language: 3\n",
            "leaders: 1\n",
            "learn: 1\n",
            "lectures: 1\n",
            "light: 1\n",
            "linear: 1\n",
            "linguistic: 2\n",
            "linguistics: 1\n",
            "logic: 1\n",
            "logical: 1\n",
            "magnetic: 1\n",
            "magnetics: 1\n",
            "magnetism: 2\n",
            "management: 1\n",
            "manner: 1\n",
            "material: 1\n",
            "materials: 1\n",
            "mathematical: 9\n",
            "mathematics: 5\n",
            "matter: 1\n",
            "measurement: 1\n",
            "mechanics: 4\n",
            "mechanisms: 1\n",
            "media: 1\n",
            "medical: 1\n",
            "methods: 1\n",
            "microdevice: 1\n",
            "microwave: 1\n",
            "mindset: 1\n",
            "modern: 2\n",
            "molecular: 1\n",
            "motion: 1\n",
            "multimedia: 1\n",
            "multiple: 1\n",
            "nano: 4\n",
            "nanodevice: 1\n",
            "nanostructure: 1\n",
            "natural: 2\n",
            "networking: 1\n",
            "new: 4\n",
            "non: 2\n",
            "nonlinear: 1\n",
            "of: 22\n",
            "on: 4\n",
            "open: 1\n",
            "optical: 1\n",
            "our: 4\n",
            "part: 1\n",
            "particles: 1\n",
            "performing: 1\n",
            "pertaining: 1\n",
            "photonics: 4\n",
            "physical: 2\n",
            "physics: 18\n",
            "plasma: 2\n",
            "play: 1\n",
            "plus: 1\n",
            "power: 2\n",
            "practical: 1\n",
            "precision: 1\n",
            "principles: 3\n",
            "problems: 1\n",
            "processing: 8\n",
            "produce: 1\n",
            "program: 13\n",
            "programming: 1\n",
            "programs: 3\n",
            "properties: 3\n",
            "quantum: 5\n",
            "range: 4\n",
            "ray: 1\n",
            "refine: 1\n",
            "related: 2\n",
            "research: 1\n",
            "resources: 2\n",
            "robotics: 1\n",
            "running: 1\n",
            "science: 10\n",
            "sciences: 6\n",
            "scientific: 1\n",
            "security: 2\n",
            "seek: 1\n",
            "semiconductor: 1\n",
            "seminars: 1\n",
            "serve: 1\n",
            "silicon: 1\n",
            "simulation: 2\n",
            "skills: 3\n",
            "smart: 1\n",
            "so: 1\n",
            "society: 3\n",
            "software: 5\n",
            "solid: 2\n",
            "specialization: 1\n",
            "spectroscopy: 1\n",
            "state: 2\n",
            "statistical: 1\n",
            "strive: 1\n",
            "strives: 1\n",
            "strong: 1\n",
            "structure: 1\n",
            "structures: 1\n",
            "students: 5\n",
            "study: 2\n",
            "subjects: 1\n",
            "such: 3\n",
            "superconductive: 1\n",
            "superconductivity: 3\n",
            "superfine: 1\n",
            "surface: 1\n",
            "system: 7\n",
            "systematically: 1\n",
            "systems: 4\n",
            "technologies: 1\n",
            "technology: 4\n",
            "telecommunications: 3\n",
            "that: 1\n",
            "the: 20\n",
            "their: 2\n",
            "them: 1\n",
            "theoretical: 3\n",
            "theory: 5\n",
            "thereby: 1\n",
            "these: 1\n",
            "they: 1\n",
            "through: 1\n",
            "to: 9\n",
            "topological: 1\n",
            "topology: 1\n",
            "trains: 1\n",
            "transmission: 1\n",
            "undergraduate: 1\n",
            "underlies: 1\n",
            "underlying: 1\n",
            "understanding: 1\n",
            "uniquely: 1\n",
            "utilization: 1\n",
            "variety: 1\n",
            "various: 2\n",
            "visual: 2\n",
            "wave: 1\n",
            "we: 1\n",
            "welcome: 1\n",
            "well: 1\n",
            "which: 1\n",
            "who: 4\n",
            "wide: 4\n",
            "with: 2\n",
            "working: 1\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from bisect import bisect_left\n",
        "\n",
        "def count_words_linear(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read().lower()\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    counts = {}\n",
        "    for word in words:\n",
        "        if word not in counts:\n",
        "            counts[word] = 1\n",
        "        else:\n",
        "            counts[word] += 1\n",
        "    return counts\n",
        "\n",
        "def count_words(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read().lower()\n",
        "    words = sorted(re.findall(r'\\b\\w+\\b', text))\n",
        "    word_counts = {}\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        word = words[i]\n",
        "        count = 1\n",
        "        while i + 1 < len(words) and words[i + 1] == word:\n",
        "            i += 1\n",
        "            count += 1\n",
        "        word_counts[word] = count\n",
        "        i += 1\n",
        "    return word_counts\n",
        "\n",
        "\n",
        "def output(word_counts):\n",
        "    for word, count in word_counts.items():\n",
        "        print(f\"{word}: {count}\")\n",
        "\n",
        "print(\"Coll_of_ES_EPs.txtファイルの文字数は:\")\n",
        "word_counts_linear = count_words_linear(\"Coll_of_ES_EPs.txt\")\n",
        "output(word_counts_linear)\n",
        "\n",
        "print(\"Dep_of_M-P-EE-CS.txtファイルの文字数は:\")\n",
        "word_counts_binary = count_words(\"Dep_of_M-P-EE-CS.txt\")\n",
        "output(word_counts_binary)\n"
      ]
    }
  ]
}